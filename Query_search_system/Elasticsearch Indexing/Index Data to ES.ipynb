{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime\n",
    "es = Elasticsearch()\n",
    "\n",
    "class tutorial:\n",
    "    # create an instance of elasticsearch and assign it to port 9200\n",
    "    ES_HOST = {\"host\": \"localhost\", \"port\": 9200}\n",
    "    es = Elasticsearch(hosts=[ES_HOST])\n",
    "\n",
    "\n",
    "    def create_index(index_name):\n",
    "        \"\"\"Functionality to create index.\"\"\"\n",
    "        resp = es.indices.create(index=index_name)\n",
    "        print(resp)\n",
    "\n",
    "\n",
    "    def document_add(index_name, doc_type, doc, doc_id=None):\n",
    "        \"\"\"Funtion to add a document by providing index_name,\n",
    "        document type, document contents as doc and document id.\"\"\"\n",
    "        resp = es.index(index=index_name, doc_type=doc_type, body=doc, id=doc_id)\n",
    "        #print(resp)\n",
    "\n",
    "\n",
    "    def document_view(index_name, doc_type, doc_id):\n",
    "        \"\"\"Function to view document.\"\"\"\n",
    "        resp = es.get(index=index_name, doc_type=doc_type, id=doc_id)\n",
    "        document = resp[\"_source\"]['Post']\n",
    "        print(document)\n",
    "\n",
    "\n",
    "    def document_update(index_name, doc_type, doc_id, doc=None, new=None):\n",
    "        \"\"\"Function to edit a document either updating existing fields or adding a new field.\"\"\"\n",
    "        if doc:\n",
    "            resp = es.index(index=index_name, doc_type=doc_type,\n",
    "                            id=doc_id, body=doc)\n",
    "            print(resp)\n",
    "        else:\n",
    "            resp = es.update(index=index_name, doc_type=doc_type,\n",
    "                             id=doc_id, body={\"doc\": new})\n",
    "\n",
    "\n",
    "    def document_delete(index_name, doc_type, doc_id):\n",
    "        \"\"\"Function to delete a specific document.\"\"\"\n",
    "        resp = es.delete(index=index_name, doc_type=doc_type, id=doc_id)\n",
    "        print(resp)\n",
    "\n",
    "\n",
    "    def delete_index(index_name):\n",
    "        \"\"\"Delete an index by specifying the index name\"\"\"\n",
    "        resp = es.indices.delete(index=index_name)\n",
    "        print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "resp = es.indices.delete(index='test')\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'test'}\n"
     ]
    }
   ],
   "source": [
    "tutorial.create_index('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "with open('tagged_data.json') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    for p in data:\n",
    "        tutorial.document_add('test', 'nvda', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3199 documents found\n",
      "tELOF2oBS2JQIYXrIZ8a) hangout accessibility nvda i am signed chrome install google hangout extension see it\n",
      "CELOF2oBS2JQIYXrHZ8M) google hangout computer using nvdait screen reader command command shortcut google hangout think mute un mute microphone\n",
      "LkLNF2oBS2JQIYXrPX2e) attempting instal google hangout plugin firefox first installed hangout software firefox browser closed called google voice video setup downloaded installed it next open firefox google hangout address is http hangout google com page wear one log start voice video call trying download hangout desktop application apparently exist got sent google voice video setup program clicked it need sign google use hangout google voice video program zipped gvavs zip uploaded send space one want firefox password google link below gvavs zip pete\n",
      "LELNF2oBS2JQIYXrPX2S) attempting instal google hangout plugin firefox hello able get hangout google com work making video call able get shortcut key work described http support google com hangout answer 3112005 rd 1 i am really sure shortcut supposed work interfere browser specific hotkeys supposed work hangout chrome app app seem accessible nvda\n",
      "-ULOF2oBS2JQIYXrHJ6h) google hangout computer using nvda i have used hangout chrome extension hangout google com hangout integrated gmail com accessible screen reader\n",
      "CULOF2oBS2JQIYXrHZ8S) google hangout computer using nvda say screen reader command said that firefox internet explorer chrome itself browser command whoever designed command google hangout determined command assigned google hangout browser command used command evidently google hangout accessed browser run browser gene\n",
      "LULNF2oBS2JQIYXrPX2Y) attempting instal google hangout plugin firefox sun mar 27 2016 2 39 nimer jaber lt nimerjaber1 gt wrote hello able get hangout google com work making video call able get shortcut key work focus mode described http support google com hangout answer 3112005 rd 1 i am really sure shortcut supposed work interfere browser specific hotkeys one conflict supposed work hangout chrome app app seem accessible nvda i have use hangout integrated gmail com hangout google com\n",
      "CkLOF2oBS2JQIYXrHZ8Z) google hangout computer using nvdathese hot key worked old ui new video call control they are fully accessible accessible hangout google com hangout gmail com chrome\n",
      "MELNF2oBS2JQIYXrPX2p) attempting instal google hangout plugin firefoxhi every one might help trick master google hangout lifehacker australia pete\n",
      "N0LNF2oBS2JQIYXrPX3P) attempting instal google hangout plugin firefox attempt use hangout firefox chrome desktop app pretty much extension chrome keep running chrome window open running background direct link chrome desktop app chrome store click browser chrome notified top store webpage you need chrome install apps extension theme link presented download chrome browser itself add ons firefox a opposed extension chrome related hangout are far see written third party use third party add ons do done google service browser brian\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    " \n",
    "es = Elasticsearch()\n",
    "\n",
    "search_qry = \"install google hangout\"\n",
    "\n",
    "res = es.search(index=\"test\", body={\"query\": {\"match\": {'Post':search_qry}}})\n",
    "\n",
    "print(\"%d documents found\" % res['hits']['total'])\n",
    "for doc in res['hits']['hits']:\n",
    "    print(\"%s) %s\" % (doc['_id'], doc['_source']['Original_post']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "SW_LIST = ['firefox', 'chrome', 'microsoft edge', 'opera', 'internet explorer', 'waterfox', 'microsoft office',\n",
    "           'microsoft word', 'microsoft excel', 'microsoft powerpoint', 'browser']\n",
    "\n",
    "def return_conversions_for_query(query):\n",
    "    es = Elasticsearch()\n",
    "    \n",
    "    sw_name = []\n",
    "    other_words = []\n",
    "    for word in query.split():\n",
    "        if word in SW_LIST:\n",
    "            sw_name.append(word)\n",
    "        else:\n",
    "            synonyms = wordnet.synsets(word)\n",
    "            lemmas = list(set(chain.from_iterable([w.lemma_names() for w in synonyms])))[:5]\n",
    "            other_words.extend(lemmas)\n",
    "            #other_words.extend(word)\n",
    "    \n",
    "    sw_name = ' '.join(sw_name)\n",
    "    other_words = ' '.join(other_words)\n",
    "    #print(sw_name)\n",
    "    #print(other_words)\n",
    "    res = es.search(index=\"test\", body={\"min_score\": 1, \"query\": {\"match\": {'Post': {\"query\": query,\n",
    "                                                    }}}})\n",
    "    \n",
    "#     res = es.search(index=\"test\", body={\"query\": {\n",
    "#                                     'bool': {\n",
    "#                                           'must': {\n",
    "#                                             'match': {'Post': sw_name}\n",
    "#                                           },\n",
    "#                                           'should': {\n",
    "#                                             'term': {'Post': other_words}\n",
    "#                                           }\n",
    "#                                         }}})\n",
    "    \n",
    "    print(\"%d documents found\" % res['hits']['total'])\n",
    "    \n",
    "    conversation =[]\n",
    "    \n",
    "    for doc in res['hits']['hits']:\n",
    "        #print(\"%s) %s\" % (doc['_id'], doc['_source']))\n",
    "        conversation.append(doc['_source'])\n",
    "    \n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430 documents found\n",
      "10\n",
      "https://nvda.groups.io/g/nvda/message/10099\n",
      "https://nvda.groups.io/g/nvda/message/13697\n",
      "https://nvda.groups.io/g/nvda/message/32370\n",
      "https://nvda.groups.io/g/nvda/message/27251\n",
      "https://nvda.groups.io/g/nvda/message/1225\n",
      "https://nvda.groups.io/g/nvda/message/17132\n",
      "https://nvda.groups.io/g/nvda/message/29192\n",
      "https://nvda.groups.io/g/nvda/message/17883\n",
      "https://nvda.groups.io/g/nvda/message/22631\n",
      "https://nvda.groups.io/g/nvda/message/27525\n"
     ]
    }
   ],
   "source": [
    "res = return_conversions_for_query(\" spellcheck error word 2003\")\n",
    "print(len(res))\n",
    "for r in res:\n",
    "    print(r['Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_help(row):\n",
    "    KEY = ['help','question','questions', 'problem','problems','bug', 'crush', 'not working']\n",
    "    for h in KEY:\n",
    "        if h in row:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_announcement(row):\n",
    "    KEY = ['announcement','announcements','release', 'nvdacon','introducing']\n",
    "    for h in KEY:\n",
    "        if h in row:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' :  ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_post_for_prediction(post):\n",
    "    \n",
    "    post = post.lower()\n",
    "    post = post.replace('[^\\w\\s]',' ')\n",
    "    post = [item for item in post.split()]\n",
    "    post = ' '.join(post)\n",
    "    print(post)\n",
    "    \n",
    "    \n",
    "    #numerical feature engineering\n",
    "    #total length of sentence\n",
    "    df['length'] = df['Post'].apply(lambda x: len(x))\n",
    "    #get number of words\n",
    "    #df['words'] = df['Post'].apply(lambda x: len(x.split(' ')))\n",
    "    df['words_not_stopword'] = df['Post'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
    "    #get the average word length\n",
    "    #df['avg_word_length'] = df['Post'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    #get the average word length\n",
    "    \n",
    "    #df['stemmed'] = df[\"Post\"].apply(lambda x: [stemmer.stem(y) for y in x.split()])\n",
    "    #df['stemmed'] = df['stemmed'].apply(' '.join)\n",
    "    \n",
    "    df['Post'] = df[\"Post\"].apply(lambda x: [wordnet_lemmatizer.lemmatize(y) for y in x.split()])\n",
    "    df['Post'] = df['Post'].apply(' '.join)\n",
    "    \n",
    "    df['is_help'] = df['Post'].apply(is_help)\n",
    "    df['is_announcement'] = df['Post'].apply(is_announcement)\n",
    "    \n",
    "    #df['char_count'] = df['Post'].apply(len)\n",
    "    #df['word_count'] = df['Post'].apply(lambda x: len(x.split()))\n",
    "    #df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
    "    df['punctuation_count'] = df['Post'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "    #df['title_word_count'] = df['Post'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "    #df['upper_case_word_count'] = df['Post'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "    df['noun_count'] = df['Post'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "    df['verb_count'] = df['Post'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "    df['adj_count'] = df['Post'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "    df['adv_count'] = df['Post'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "    df['pron_count'] = df['Post'].apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometime 909090 I’m using computer and NVDA has spoken but when sighted person looking my monitor it’s not match it very hard to tell sighted person when sometime might to teaching some software for sighted person When the sighted person teaching a computer they using mouse for pointing somewhere So if we are the blind people can we do like this with nvda such as I want to tell them go to save as menu and I want to point the mouse on this could we do like this?\n"
     ]
    }
   ],
   "source": [
    "process_post_for_prediction(\"Sometime  909090  I’m using computer and NVDA has spoken but when sighted person looking my monitor it’s not match it very hard to tell sighted person when sometime might to teaching some software for sighted person When the sighted person teaching a computer they using mouse for pointing somewhere So if we are the blind people can we do like this with nvda such as  I want to tell them go to save as menu and I want to point the mouse on this could we do like this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def predict_class(post):\n",
    "    # load model from file\n",
    "    loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))\n",
    "    # make predictions for test data\n",
    "    y_pred = loaded_model.predict(X_data)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
